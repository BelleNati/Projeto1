{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Isabelle Moschini Murollo\n",
    "\n",
    "Nome: Maia Fleider\n",
    "\n",
    "Nome: Natália Queiroz Menezes Carreras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo catupiry.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "catupiry = 'catupiry.xlsx'\n",
    "if catupiry in os.listdir():\n",
    "    print(f'Encontrei o arquivo {catupiry}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {catupiry} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>RELEVANCIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>viciei em hambúrguer com catupiry rota, por qu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@balalirica empadão de frango com catupiry fei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coisas inúteis sobre mim\\naltura — 1,78\\nidade...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uma pizza de frango com catupiry no café da manhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nossa queria uma pizza de frango com catupiry ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  RELEVANCIA\n",
       "0  viciei em hambúrguer com catupiry rota, por qu...           3\n",
       "1  @balalirica empadão de frango com catupiry fei...           1\n",
       "2  coisas inúteis sobre mim\\naltura — 1,78\\nidade...           2\n",
       "3  uma pizza de frango com catupiry no café da manhã           1\n",
       "4  nossa queria uma pizza de frango com catupiry ...           2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(catupiry)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>RELEVANCIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoje eu sonhei que tava de rolê aqui pertinho ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@essediafoilouco pizza de frango com catupiry ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jubaqueen frango com catupiry e banana com ca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@df_porto a @tweetsdaphri não é mineira, mas é...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>isso aqui! (tirando a parte de encher a cara, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  RELEVANCIA\n",
       "0  hoje eu sonhei que tava de rolê aqui pertinho ...           0\n",
       "1  @essediafoilouco pizza de frango com catupiry ...           2\n",
       "2  @jubaqueen frango com catupiry e banana com ca...           2\n",
       "3  @df_porto a @tweetsdaphri não é mineira, mas é...           0\n",
       "4  isso aqui! (tirando a parte de encher a cara, ...           0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(catupiry, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nós consideramos que os tweets mais relevantes para o produto seriam aqueles que realizassem comentários positivos ou comentários negativos, enquanto os menos relevantes seriam não relacionados diretamente ao produto.\n",
    "\n",
    "Assim, construímos a seguinte escala:\n",
    "\n",
    "0 - comentários não relacionados (irrelevante)\n",
    "\n",
    "1 - comentários neutros ou que não agregassem ao produto (neutro)\n",
    "\n",
    "2 - comentários positivos e elogios (relevante)\n",
    "\n",
    "3 - comentários que envolviam sentimentos positivos muito fortes ou comentários negativos (muito relevante)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importando as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorizando as classificações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para o treinamento\n",
    "train['RELEVANCIA']=train['RELEVANCIA'].astype('category')\n",
    "\n",
    "train['RELEVANCIA'].cat.categories = ['Irrelevante', 'Neutro', 'Relevante', 'Muito Relevante']\n",
    "\n",
    "filtra_irrelevantes = train['RELEVANCIA']=='Irrelevante'\n",
    "filtra_neutro = train['RELEVANCIA']=='Neutro'\n",
    "filtra_relevante = train['RELEVANCIA']=='Relevante'\n",
    "filtra_muito_relevante = train['RELEVANCIA']=='Muito Relevante'\n",
    "\n",
    "irrelevante = train.loc[filtra_irrelevantes,:]\n",
    "neutro = train.loc[filtra_neutro,:]\n",
    "relevante = train.loc[filtra_relevante,:]\n",
    "muito_relevante = train.loc[filtra_muito_relevante,:]\n",
    "\n",
    "#Para o teste\n",
    "test['RELEVANCIA']=test['RELEVANCIA'].astype('category')\n",
    "\n",
    "test['RELEVANCIA'].cat.categories = ['Irrelevante', 'Neutro', 'Relevante', 'Muito Relevante']\n",
    "\n",
    "filtra_irrelevantes_teste = test['RELEVANCIA']=='Irrelevante'\n",
    "filtra_neutro_teste = test['RELEVANCIA']=='Neutro'\n",
    "filtra_relevante_teste = test['RELEVANCIA']=='Relevante'\n",
    "filtra_muito_relevante_teste = test['RELEVANCIA']=='Muito Relevante'\n",
    "\n",
    "irrelevante_teste = test.loc[filtra_irrelevantes_teste,:]\n",
    "neutro_teste = test.loc[filtra_neutro_teste,:]\n",
    "relevante_teste = test.loc[filtra_relevante_teste,:]\n",
    "muito_relevante_teste = test.loc[filtra_muito_relevante_teste,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imprimindo as classificações categorizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(irrelevante)\\nprint(neutro)\\nprint(relevante)\\nprint(muito_relevante)\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(irrelevante)\n",
    "print(neutro)\n",
    "print(relevante)\n",
    "print(muito_relevante)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criando as funções para limpeza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "#REMOVENDO PONTUAÇÕES:\n",
    "def cleanup(tweet):\n",
    "    punctuation = '[!-.:?;\\\"\\n()\\',—•]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    tweet_subbed = re.sub(pattern, '', tweet)\n",
    "    return tweet_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhttp(tweet):\n",
    "    site = 'http[^\\s]*'\n",
    "    pattern = re.compile(site)\n",
    "    tweet_subbed_site = re.sub(pattern, '', tweet)\n",
    "    return tweet_subbed_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_emoji(texto):\n",
    "    novo_texto = ''\n",
    "    for character in texto:\n",
    "        if character in emoji.UNICODE_EMOJI:\n",
    "            novo_texto += ' ' + character + ' '\n",
    "        else:\n",
    "            novo_texto += character\n",
    "    return novo_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_palavras(tweet):\n",
    "    palavras = tweet.split()\n",
    "    novo_tweet = ''\n",
    "    lista = ['a', 'e', 'o', 'em', 'de', 'da', 'do', 'eh', 'é', 'que', 'q', 'pra', 'pro', 'para', 'com', 'cm', 'por']\n",
    "    for palavra in palavras:\n",
    "        if palavra in lista:\n",
    "            novo_tweet += ''\n",
    "        else:\n",
    "            novo_tweet += palavra\n",
    "    return novo_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_palavras2(lista):\n",
    "    nova_lista = []\n",
    "    lista_palavras = ['a', 'e', 'o', 'em', 'de', 'da', 'do', 'eh', 'é', 'que', 'q', 'pra', 'pro', 'para', 'com', 'cm', 'por']\n",
    "    for palavra in lista:\n",
    "        if palavra in lista_palavras:\n",
    "            nova_lista.append('')\n",
    "        else:\n",
    "            nova_lista.append(palavra)\n",
    "    return nova_lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementando as funções para limpeza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espaçando as frases uma das outras:\n",
    "treinamento_string = \"\"\n",
    "for tweet in train.Treinamento:\n",
    "    treinamento_string += \" \"+tweet\n",
    "    \n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower = cleanup(treinamento_string.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site = cleanhttp(treinamento_lower)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis = clean_emoji(treinamento_site)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento = treinamento_emojis.split()\n",
    "\n",
    "#Tirando palavras pouco relevantes, como preposições:\n",
    "tweet_sem_palavras = clean_palavras2(separacao_treinamento) #CORRIGIR\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento = pd.Series(tweet_sem_palavras)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IRRELEVANTES:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_irrelevantes = \"\"\n",
    "for i in irrelevante.Treinamento:\n",
    "    treinamento_irrelevantes += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_irrelevantes = cleanup(treinamento_irrelevantes.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_irrelevantes = cleanhttp(treinamento_lower_irrelevantes)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_irrelevantes = clean_emoji(treinamento_site_irrelevantes)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_irrelevantes = treinamento_emojis_irrelevantes.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_irrelevantes = pd.Series(separacao_treinamento_irrelevantes)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEUTRO:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_neutro = \"\"\n",
    "for i in neutro.Treinamento:\n",
    "    treinamento_neutro += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_neutro = cleanup(treinamento_neutro.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_neutro = cleanhttp(treinamento_lower_neutro)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_neutro = clean_emoji(treinamento_site_neutro)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_neutro = treinamento_emojis_neutro.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_neutro = pd.Series(separacao_treinamento_neutro)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(serie_treinamento_neutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RELEVANTES:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_relevantes = \"\"\n",
    "for i in relevante.Treinamento:\n",
    "    treinamento_relevantes += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_relevantes = cleanup(treinamento_relevantes.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_relevantes = cleanhttp(treinamento_lower_relevantes)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_relevantes = clean_emoji(treinamento_site_relevantes)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_relevantes = treinamento_emojis_relevantes.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_relevantes = pd.Series(separacao_treinamento_relevantes)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUITO RELEVANTES:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_muito_relevantes = \"\"\n",
    "for i in muito_relevante.Treinamento:\n",
    "    treinamento_muito_relevantes += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_muito_relevantes = cleanup(treinamento_muito_relevantes.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_muito_relevantes = cleanhttp(treinamento_lower_muito_relevantes)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_muito_relevantes = clean_emoji(treinamento_site_muito_relevantes)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_muito_relevantes = treinamento_emojis_muito_relevantes.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_muito_relevantes = pd.Series(separacao_treinamento_muito_relevantes)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento_muito_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabelas de frequencias absolutas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de treinamento:\n",
    "frequencia_absoluta_total = serie_treinamento.value_counts()\n",
    "\n",
    "# Tabela de tweets irrelevantes:\n",
    "frequencia_absoluta_irrelevante = serie_treinamento_irrelevantes.value_counts()\n",
    "\n",
    "# Tabela de tweets neutros:\n",
    "frequencia_absoluta_neutro = serie_treinamento_neutro.value_counts()\n",
    "\n",
    "# Tabela de tweets relevantes:  \n",
    "frequencia_absoluta_relevante = serie_treinamento_relevantes.value_counts()\n",
    "    \n",
    "# Tabela de tweets irrelevantes:\n",
    "frequencia_absoluta_muito_relevante = serie_treinamento_muito_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_neutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_relevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_muito_relevante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Teorema Naive-Bayes:\n",
    "###### Adicionando variáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1e-6   \n",
    "v = 1e6  #palavras totais na língua portuguesa/usadas no twitter\n",
    "\n",
    "lista_NB = [] #lista do Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando as probabilidades\n",
    "P_irrelevante = frequencia_absoluta_irrelevante.sum() / frequencia_absoluta_total.sum()\n",
    "P_neutro = frequencia_absoluta_neutro.sum() / frequencia_absoluta_total.sum()\n",
    "P_relevante = frequencia_absoluta_relevante.sum() / frequencia_absoluta_total.sum()\n",
    "P_muito_relevante = frequencia_absoluta_muito_relevante.sum() / frequencia_absoluta_total.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(P_irrelevante)\\nprint(P_neutro)\\nprint(P_relevante)\\nprint(P_muito_relevante)\\nprint(P_irrelevante+P_neutro+P_relevante+P_muito_relevante)\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(P_irrelevante)\n",
    "print(P_neutro)\n",
    "print(P_relevante)\n",
    "print(P_muito_relevante)\n",
    "print(P_irrelevante+P_neutro+P_relevante+P_muito_relevante)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(irrelevante_teste)\\nprint(neutro_teste)\\nprint(relevante_teste)\\nprint(muito_relevante_teste)\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(irrelevante_teste)\n",
    "print(neutro_teste)\n",
    "print(relevante_teste)\n",
    "print(muito_relevante_teste)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   \\nif score(tweet, P_tweet_dado_irrelevante, P_irrelevante) > score(tweet, P_tweet_dado_relevante, P_relevante)     and P_irrelevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet     and P_irrelevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\\n    lista_NB.append(\"Irrelevante\")\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import *\n",
    "\n",
    "def score(tweet, prob, prior):\n",
    "    log1 = 0\n",
    "    for palavra in tweet:\n",
    "        log1 += log(prob) #somatória\n",
    "        \n",
    "    log2 = log(prior)\n",
    "    \n",
    "    log3 = log(a/(frequencia_absoluta_total + a*v))\n",
    "    \n",
    "    return (log1 + log2 + log3)\n",
    "    \n",
    "    #P_irrelevante_dado_tweet_vezes_P_tweet = P_tweet_dado_irrelevante*P_irrelevante\n",
    "'''   \n",
    "if score(tweet, P_tweet_dado_irrelevante, P_irrelevante) > score(tweet, P_tweet_dado_relevante, P_relevante) \\\n",
    "    and P_irrelevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "    and P_irrelevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\n",
    "    lista_NB.append(\"Irrelevante\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O “prob” a que eu me referia é o dicionário que mapeia cada palavra para a sua probabilidade com smoothing.\n",
    "\n",
    "prob_unknown = (frequencia_absoluta_total + a*v)\n",
    "\n",
    "def score(tweet, prob, prior):\n",
    "    log1 = 0\n",
    "    for palavra in tweet:\n",
    "        if palavra in prob:\n",
    "            log1 += log(prob[palavra])\n",
    "        else:\n",
    "            log1 += log(prob_unknown)\n",
    "    return log1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in test.Teste:    \n",
    "    #Deixando tudo em letras minúsculas:\n",
    "    teste_lower = cleanup(tweet.lower())\n",
    "\n",
    "    #Apagando links:\n",
    "    teste_site = cleanhttp(teste_lower)\n",
    "\n",
    "    #Separando emojis:\n",
    "    teste_emojis = clean_emoji(teste_site)\n",
    "\n",
    "    #Separando as palavras:\n",
    "    separacao_teste = teste_emojis.split()\n",
    "    \n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser irrelevante:\n",
    "    P_tweet_dado_irrelevante = 1\n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_irrelevante:\n",
    "            P_i_dado_irrelevante = (frequencia_absoluta_irrelevante[i] + a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_irrelevante = (a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        P_tweet_dado_irrelevante *= P_i_dado_irrelevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser neutro:\n",
    "    P_tweet_dado_neutro = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_neutro:\n",
    "            P_i_dado_neutro = (frequencia_absoluta_neutro[i] + a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_neutro = (a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        P_tweet_dado_neutro *= P_i_dado_neutro\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser relevante:\n",
    "    P_tweet_dado_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_relevante:\n",
    "            P_i_dado_relevante = (frequencia_absoluta_relevante[i] + a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_relevante = (a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        P_tweet_dado_relevante *= P_i_dado_relevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser muito relevante:\n",
    "    P_tweet_dado_muito_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_muito_relevante:\n",
    "            P_i_dado_muito_relevante = (frequencia_absoluta_muito_relevante[i] + a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_muito_relevante = (a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        P_tweet_dado_muito_relevante *= P_i_dado_muito_relevante\n",
    "        \n",
    "        \n",
    "    dic_tweet_irrelevante = {}\n",
    "    dic_tweet_neutro = {}\n",
    "    dic_tweet_relevante = {}\n",
    "    dic_tweet_muito_relevante = {}\n",
    "    \n",
    "    for palavra in tweet:\n",
    "        dic_tweet_irrelevante[palavra] = P_tweet_dado_irrelevante\n",
    "        dic_tweet_neutro[palavra] = P_tweet_dado_neutro\n",
    "        dic_tweet_relevante[palavra] = P_tweet_dado_relevante\n",
    "        dic_tweet_muito_relevante[palavra] = P_tweet_dado_muito_relevante\n",
    "        \n",
    "    # Comparando as probabilidades utilizando o método Naive-Bayes \n",
    "    if score(tweet, dic_tweet_irrelevante, P_irrelevante) > score(tweet, dic_tweet_relevante, P_relevante) \\\n",
    "        and score(tweet, dic_tweet_irrelevante, P_irrelevante) > score(tweet, dic_tweet_neutro, P_neutro) \\\n",
    "        and score(tweet, dic_tweet_irrelevante, P_irrelevante) > score(tweet, dic_tweet_muito_relevante, P_muito_relevante):\n",
    "        lista_NB.append(\"Irrelevante\")\n",
    "        \n",
    "    elif score(tweet, dic_tweet_neutro, P_neutro) > score(tweet, dic_tweet_irrelevante, P_irrelevante) \\\n",
    "        and score(tweet, dic_tweet_neutro, P_neutro) > score(tweet, dic_tweet_relevante, P_relevante) \\\n",
    "        and score(tweet, dic_tweet_neutro, P_neutro) > score(tweet, dic_tweet_muito_relevante, P_muito_relevante):\n",
    "        lista_NB.append(\"Neutro\")\n",
    "        \n",
    "    elif score(tweet, dic_tweet_relevante, P_relevante) > score(tweet, dic_tweet_irrelevante, P_irrelevante) \\\n",
    "        and score(tweet, dic_tweet_relevante, P_relevante) > score(tweet, dic_tweet_neutro, P_neutro) \\\n",
    "        and score(tweet, dic_tweet_relevante, P_relevante) > score(tweet, dic_tweet_muito_relevante, P_muito_relevante):\n",
    "        lista_NB.append(\"Relevante\")\n",
    "    \n",
    "    elif score(tweet, dic_tweet_muito_relevante, P_muito_relevante) > score(tweet, dic_tweet_irrelevante, P_irrelevante) \\\n",
    "        and score(tweet, dic_tweet_muito_relevante, P_muito_relevante) > score(tweet, dic_tweet_neutro, P_neutro) \\\n",
    "        and score(tweet, dic_tweet_muito_relevante, P_muito_relevante) > score(tweet, dic_tweet_relevante, P_relevante):\n",
    "        lista_NB.append(\"Muito Relevante\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor tweet in test.Teste:    \\n    #Deixando tudo em letras minúsculas:\\n    teste_lower = cleanup(tweet.lower())\\n\\n    #Apagando links:\\n    teste_site = cleanhttp(teste_lower)\\n\\n    #Separando emojis:\\n    teste_emojis = clean_emoji(teste_site)\\n\\n    #Separando as palavras:\\n    separacao_teste = teste_emojis.split()\\n    \\n    \\n    # Calculando a probabilidade do tweet ser irrelevante:\\n    P_tweet_dado_irrelevante = 1\\n    for i in separacao_teste:\\n        if i in frequencia_absoluta_irrelevante:\\n            P_i_dado_irrelevante = (frequencia_absoluta_irrelevante[i] + a) / (frequencia_absoluta_irrelevante.sum() + a*v)\\n        else:\\n            P_i_dado_irrelevante = (a) / (frequencia_absoluta_irrelevante.sum() + a*v)\\n        P_tweet_dado_irrelevante *= P_i_dado_irrelevante\\n    \\n    # Calculando a probabilidade do tweet ser neutro:\\n    P_tweet_dado_neutro = 1 \\n    for i in separacao_teste:\\n        if i in frequencia_absoluta_neutro:\\n            P_i_dado_neutro = (frequencia_absoluta_neutro[i] + a) / (frequencia_absoluta_neutro.sum() + a*v)\\n        else:\\n            P_i_dado_neutro = (a) / (frequencia_absoluta_neutro.sum() + a*v)\\n        P_tweet_dado_neutro *= P_i_dado_neutro\\n    \\n    # Calculando a probabilidade do tweet ser relevante:\\n    P_tweet_dado_relevante = 1 \\n    for i in separacao_teste:\\n        if i in frequencia_absoluta_relevante:\\n            P_i_dado_relevante = (frequencia_absoluta_relevante[i] + a) / (frequencia_absoluta_relevante.sum() + a*v)\\n        else:\\n            P_i_dado_relevante = (a) / (frequencia_absoluta_relevante.sum() + a*v)\\n        P_tweet_dado_relevante *= P_i_dado_relevante\\n    \\n    # Calculando a probabilidade do tweet ser muito relevante:\\n    P_tweet_dado_muito_relevante = 1 \\n    for i in separacao_teste:\\n        if i in frequencia_absoluta_muito_relevante:\\n            P_i_dado_muito_relevante = (frequencia_absoluta_muito_relevante[i] + a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\\n        else:\\n            P_i_dado_muito_relevante = (a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\\n        P_tweet_dado_muito_relevante *= P_i_dado_muito_relevante\\n        \\n        \\n    # Comparando as probabilidades utilizando o método Naive-Bayes \\n    P_irrelevante_dado_tweet_vezes_P_tweet = P_tweet_dado_irrelevante*P_irrelevante\\n    P_neutro_dado_tweet_vezes_P_tweet = P_tweet_dado_neutro*P_neutro\\n    P_relevante_dado_tweet_vezes_P_tweet = P_tweet_dado_relevante*P_relevante\\n    P_muito_relevante_dado_tweet_vezes_P_tweet = P_tweet_dado_muito_relevante*P_muito_relevante\\n    \\n    if  P_irrelevante_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet         and P_irrelevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet         and P_irrelevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\\n        lista_NB.append(\"Irrelevante\")\\n        \\n    if P_neutro_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet         and P_neutro_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet         and P_neutro_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\\n        lista_NB.append(\"Neutro\")\\n        \\n    if P_relevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet         and P_relevante_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet         and P_relevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet :\\n        lista_NB.append(\"Relevante\")\\n    \\n    if P_muito_relevante_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet         and P_muito_relevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet         and P_muito_relevante_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet:\\n        lista_NB.append(\"Muito Relevante\")\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for tweet in test.Teste:    \n",
    "    #Deixando tudo em letras minúsculas:\n",
    "    teste_lower = cleanup(tweet.lower())\n",
    "\n",
    "    #Apagando links:\n",
    "    teste_site = cleanhttp(teste_lower)\n",
    "\n",
    "    #Separando emojis:\n",
    "    teste_emojis = clean_emoji(teste_site)\n",
    "\n",
    "    #Separando as palavras:\n",
    "    separacao_teste = teste_emojis.split()\n",
    "    \n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser irrelevante:\n",
    "    P_tweet_dado_irrelevante = 1\n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_irrelevante:\n",
    "            P_i_dado_irrelevante = (frequencia_absoluta_irrelevante[i] + a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_irrelevante = (a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        P_tweet_dado_irrelevante *= P_i_dado_irrelevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser neutro:\n",
    "    P_tweet_dado_neutro = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_neutro:\n",
    "            P_i_dado_neutro = (frequencia_absoluta_neutro[i] + a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_neutro = (a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        P_tweet_dado_neutro *= P_i_dado_neutro\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser relevante:\n",
    "    P_tweet_dado_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_relevante:\n",
    "            P_i_dado_relevante = (frequencia_absoluta_relevante[i] + a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_relevante = (a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        P_tweet_dado_relevante *= P_i_dado_relevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser muito relevante:\n",
    "    P_tweet_dado_muito_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_muito_relevante:\n",
    "            P_i_dado_muito_relevante = (frequencia_absoluta_muito_relevante[i] + a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_muito_relevante = (a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        P_tweet_dado_muito_relevante *= P_i_dado_muito_relevante\n",
    "        \n",
    "        \n",
    "    # Comparando as probabilidades utilizando o método Naive-Bayes \n",
    "    P_irrelevante_dado_tweet_vezes_P_tweet = P_tweet_dado_irrelevante*P_irrelevante\n",
    "    P_neutro_dado_tweet_vezes_P_tweet = P_tweet_dado_neutro*P_neutro\n",
    "    P_relevante_dado_tweet_vezes_P_tweet = P_tweet_dado_relevante*P_relevante\n",
    "    P_muito_relevante_dado_tweet_vezes_P_tweet = P_tweet_dado_muito_relevante*P_muito_relevante\n",
    "    \n",
    "    if  P_irrelevante_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_irrelevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "        and P_irrelevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\n",
    "        lista_NB.append(\"Irrelevante\")\n",
    "        \n",
    "    if P_neutro_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_neutro_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_neutro_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\n",
    "        lista_NB.append(\"Neutro\")\n",
    "        \n",
    "    if P_relevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "        and P_relevante_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_relevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet :\n",
    "        lista_NB.append(\"Relevante\")\n",
    "    \n",
    "    if P_muito_relevante_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_muito_relevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "        and P_muito_relevante_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet:\n",
    "        lista_NB.append(\"Muito Relevante\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Muito Relevante\n",
       "1               Neutro\n",
       "2            Relevante\n",
       "3               Neutro\n",
       "4            Relevante\n",
       "            ...       \n",
       "663        Irrelevante\n",
       "664             Neutro\n",
       "665        Irrelevante\n",
       "666          Relevante\n",
       "667        Irrelevante\n",
       "Name: RELEVANCIA, Length: 668, dtype: category\n",
       "Categories (4, object): [Irrelevante, Neutro, Relevante, Muito Relevante]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['RELEVANCIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>RELEVANCIA</th>\n",
       "      <th>RELEVANCIA (Naive Bayes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoje eu sonhei que tava de rolê aqui pertinho ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@essediafoilouco pizza de frango com catupiry ...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jubaqueen frango com catupiry e banana com ca...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@df_porto a @tweetsdaphri não é mineira, mas é...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>isso aqui! (tirando a parte de encher a cara, ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste   RELEVANCIA  \\\n",
       "0  hoje eu sonhei que tava de rolê aqui pertinho ...  Irrelevante   \n",
       "1  @essediafoilouco pizza de frango com catupiry ...    Relevante   \n",
       "2  @jubaqueen frango com catupiry e banana com ca...    Relevante   \n",
       "3  @df_porto a @tweetsdaphri não é mineira, mas é...  Irrelevante   \n",
       "4  isso aqui! (tirando a parte de encher a cara, ...  Irrelevante   \n",
       "\n",
       "  RELEVANCIA (Naive Bayes)  \n",
       "0                Relevante  \n",
       "1          Muito Relevante  \n",
       "2          Muito Relevante  \n",
       "3                   Neutro  \n",
       "4              Irrelevante  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['RELEVANCIA (Naive Bayes)'] = lista_NB\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Relevante\n",
       "1      Muito Relevante\n",
       "2      Muito Relevante\n",
       "3               Neutro\n",
       "4          Irrelevante\n",
       "            ...       \n",
       "330             Neutro\n",
       "331        Irrelevante\n",
       "332        Irrelevante\n",
       "333        Irrelevante\n",
       "334    Muito Relevante\n",
       "Name: RELEVANCIA (Naive Bayes), Length: 335, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['RELEVANCIA (Naive Bayes)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "total_irrelevantes = 0\n",
    "total_neutros = 0\n",
    "total_relevantes = 0\n",
    "total_muitorelevantes = 0\n",
    "\n",
    "verdadeiros_irrelevantes = 0\n",
    "falsos_irrelevantes = 0\n",
    "\n",
    "verdadeiros_neutros = 0\n",
    "falsos_neutros = 0\n",
    "\n",
    "verdadeiros_relevantes = 0\n",
    "falsos_relevantes = 0\n",
    "\n",
    "verdadeiros_muitorelevantes = 0\n",
    "falsos_muitorelevantes = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for index, row in test.iterrows():\n",
    "    if row['RELEVANCIA']==\"Irrelevante\":\n",
    "        total_irrelevantes+=1\n",
    "        \n",
    "    if row['RELEVANCIA']==\"Neutro\":\n",
    "        total_neutros+=1     \n",
    "        \n",
    "    if row['RELEVANCIA']==\"Relevante\":\n",
    "        total_relevantes+=1\n",
    "        \n",
    "    if row['RELEVANCIA']==\"Muito Relevante\":\n",
    "        total_muitorelevantes+=1\n",
    "        \n",
    "        \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Irrelevante\":\n",
    "        if row['RELEVANCIA']==\"Irrelevante\":\n",
    "            verdadeiros_irrelevantes+=1\n",
    "        else:\n",
    "            falsos_irrelevantes+=1\n",
    "    \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Neutro\":\n",
    "        if row['RELEVANCIA']==\"Neutro\":\n",
    "            verdadeiros_neutros+=1\n",
    "        else:\n",
    "            falsos_neutros+=1\n",
    "    \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Relevante\":\n",
    "        if row['RELEVANCIA']==\"Relevante\":\n",
    "            verdadeiros_relevantes+=1\n",
    "        else:\n",
    "            falsos_relevantes+=1\n",
    "        \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Muito Relevante\":\n",
    "        if row['RELEVANCIA']==\"Muito Relevante\":\n",
    "            verdadeiros_muitorelevantes+=1\n",
    "        else:\n",
    "            falsos_muitorelevantes+=1   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "P_verdadeiros_irrelevantes = verdadeiros_irrelevantes/total_irrelevantes\n",
    "P_falsos_irrelevantes = falsos_irrelevantes/total_irrelevantes\n",
    "\n",
    "P_verdadeiros_neutros = verdadeiros_neutros/total_neutros\n",
    "P_falsos_neutros = falsos_neutros/total_neutros\n",
    "\n",
    "P_verdadeiros_relevantes = verdadeiros_relevantes/total_relevantes\n",
    "P_falsos_relevantes = falsos_relevantes/total_relevantes\n",
    "\n",
    "P_verdadeiros_muitorelevantes = verdadeiros_muitorelevantes/total_muitorelevantes\n",
    "P_falsos_muitorelevantes = falsos_muitorelevantes/total_muitorelevantes\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('Mensagens irrelevantes e que são classificadas como irrelevantes: ', P_verdadeiros_irrelevantes)\n",
    "print('Mensagens irrelevantes e que NÃO são classificadas como irrelevantes: ', P_falsos_irrelevantes)\n",
    "print(P_verdadeiros_irrelevantes+P_falsos_irrelevantes)\n",
    "print()\n",
    "\n",
    "print('Mensagens neutras e que são classificadas como neutras: ', P_verdadeiros_neutros)\n",
    "print('Mensagens neutras e que NÃO são classificadas como neutras: ', P_falsos_neutros)\n",
    "print(P_verdadeiros_neutros+P_falsos_neutros)\n",
    "print()\n",
    "\n",
    "print('Mensagens relevantes e que são classificadas como relevantes: ', P_verdadeiros_relevantes)\n",
    "print('Mensagens relevantes e que NÃO são classificadas como relevantes: ', P_falsos_relevantes)\n",
    "print(P_verdadeiros_relevantes+P_falsos_relevantes)\n",
    "print()\n",
    "\n",
    "print('Mensagens muito relevantes e que são classificadas como muito relevantes: ', P_verdadeiros_muitorelevantes)\n",
    "print('Mensagens muito relevantes e que NÃO são classificadas como muito relevantes: ', P_falsos_muitorelevantes)\n",
    "print(P_verdadeiros_muitorelevantes+P_falsos_muitorelevantes)\n",
    "\n",
    "print()\n",
    "print(P_verdadeiros_muitorelevantes+P_falsos_muitorelevantes+\\\n",
    "     P_verdadeiros_relevantes+P_falsos_relevantes+\\\n",
    "     P_verdadeiros_neutros+P_falsos_neutros+\\\n",
    "     P_verdadeiros_irrelevantes+P_falsos_irrelevantes)\n",
    "\n",
    "print()\n",
    "print((P_verdadeiros_muitorelevantes+P_verdadeiros_relevantes+\\\n",
    "      P_verdadeiros_neutros+P_verdadeiros_irrelevantes)/4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>RELEVANCIA (Naive Bayes)</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Muito Relevante</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RELEVANCIA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.041791</td>\n",
       "      <td>0.071642</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>0.038806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutro</th>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.056716</td>\n",
       "      <td>0.077612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>0.068657</td>\n",
       "      <td>0.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muito Relevante</th>\n",
       "      <td>0.056716</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.047761</td>\n",
       "      <td>0.095522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "RELEVANCIA (Naive Bayes)  Irrelevante  Muito Relevante    Neutro  Relevante\n",
       "RELEVANCIA                                                                 \n",
       "Irrelevante                  0.041791         0.071642  0.041791   0.038806\n",
       "Neutro                       0.050746         0.074627  0.056716   0.077612\n",
       "Relevante                    0.065672         0.077612  0.068657   0.074627\n",
       "Muito Relevante              0.056716         0.059701  0.047761   0.095522"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela = pd.crosstab(train['RELEVANCIA'], test['RELEVANCIA (Naive Bayes)'], normalize='all')\n",
    "tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23.400000000000002%'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{(tabela.iloc[0,0] + tabela.iloc[1,2] + tabela.iloc[2,3] + tabela.iloc[3,1])*100.5}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RELEVANCIA</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Muito Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Teste</th>\n",
       "      <th>count</th>\n",
       "      <td>68</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>rt @papoinverso: tem episódo novo do #papoinve...</td>\n",
       "      <td>to pensando em fazer pra semana que vem uma fo...</td>\n",
       "      <td>rt @cunhajulliana: eu posso comer qualquer sab...</td>\n",
       "      <td>@pedrohro15 não resisti, ela tinha catupiry, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">RELEVANCIA (Naive Bayes)</th>\n",
       "      <th>count</th>\n",
       "      <td>68</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "RELEVANCIA                                                             Irrelevante  \\\n",
       "Teste                    count                                                  68   \n",
       "                         unique                                                 63   \n",
       "                         top     rt @papoinverso: tem episódo novo do #papoinve...   \n",
       "                         freq                                                    2   \n",
       "RELEVANCIA (Naive Bayes) count                                                  68   \n",
       "                         unique                                                  4   \n",
       "                         top                                           Irrelevante   \n",
       "                         freq                                                   44   \n",
       "\n",
       "RELEVANCIA                                                                  Neutro  \\\n",
       "Teste                    count                                                  82   \n",
       "                         unique                                                 79   \n",
       "                         top     to pensando em fazer pra semana que vem uma fo...   \n",
       "                         freq                                                    2   \n",
       "RELEVANCIA (Naive Bayes) count                                                  82   \n",
       "                         unique                                                  4   \n",
       "                         top                                                Neutro   \n",
       "                         freq                                                   39   \n",
       "\n",
       "RELEVANCIA                                                               Relevante  \\\n",
       "Teste                    count                                                  89   \n",
       "                         unique                                                 88   \n",
       "                         top     rt @cunhajulliana: eu posso comer qualquer sab...   \n",
       "                         freq                                                    2   \n",
       "RELEVANCIA (Naive Bayes) count                                                  89   \n",
       "                         unique                                                  4   \n",
       "                         top                                             Relevante   \n",
       "                         freq                                                   35   \n",
       "\n",
       "RELEVANCIA                                                         Muito Relevante  \n",
       "Teste                    count                                                  96  \n",
       "                         unique                                                 95  \n",
       "                         top     @pedrohro15 não resisti, ela tinha catupiry, f...  \n",
       "                         freq                                                    2  \n",
       "RELEVANCIA (Naive Bayes) count                                                  96  \n",
       "                         unique                                                  4  \n",
       "                         top                                       Muito Relevante  \n",
       "                         freq                                                   44  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(by=\"RELEVANCIA\").describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RELEVANCIA (Naive Bayes)</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Muito Relevante</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Teste</th>\n",
       "      <th>count</th>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>61</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>costelinha com barbecue e queijo; e camarão co...</td>\n",
       "      <td>coisas inúteis sobre mim\\n\\naltura — 1,53\\ntam...</td>\n",
       "      <td>so pode reclamar disso quem não come pizza de ...</td>\n",
       "      <td>queria meu mo aq em casa pra nós comer uma piz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">RELEVANCIA</th>\n",
       "      <th>count</th>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Muito Relevante</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>Muito Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "RELEVANCIA (Naive Bayes)                                        Irrelevante  \\\n",
       "Teste      count                                                         72   \n",
       "           unique                                                        61   \n",
       "           top            costelinha com barbecue e queijo; e camarão co...   \n",
       "           freq                                                           2   \n",
       "RELEVANCIA count                                                         72   \n",
       "           unique                                                         4   \n",
       "           top                                                  Irrelevante   \n",
       "           freq                                                          44   \n",
       "\n",
       "RELEVANCIA (Naive Bayes)                                    Muito Relevante  \\\n",
       "Teste      count                                                         95   \n",
       "           unique                                                        90   \n",
       "           top            coisas inúteis sobre mim\\n\\naltura — 1,53\\ntam...   \n",
       "           freq                                                           2   \n",
       "RELEVANCIA count                                                         95   \n",
       "           unique                                                         4   \n",
       "           top                                              Muito Relevante   \n",
       "           freq                                                          44   \n",
       "\n",
       "RELEVANCIA (Naive Bayes)                                             Neutro  \\\n",
       "Teste      count                                                         72   \n",
       "           unique                                                        70   \n",
       "           top            so pode reclamar disso quem não come pizza de ...   \n",
       "           freq                                                           2   \n",
       "RELEVANCIA count                                                         72   \n",
       "           unique                                                         4   \n",
       "           top                                                       Neutro   \n",
       "           freq                                                          39   \n",
       "\n",
       "RELEVANCIA (Naive Bayes)                                          Relevante  \n",
       "Teste      count                                                         96  \n",
       "           unique                                                        90  \n",
       "           top            queria meu mo aq em casa pra nós comer uma piz...  \n",
       "           freq                                                           2  \n",
       "RELEVANCIA count                                                         96  \n",
       "           unique                                                         4  \n",
       "           top                                              Muito Relevante  \n",
       "           freq                                                          37  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(by=\"RELEVANCIA (Naive Bayes)\").describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faça um comparativo qualitativo sobre os percentuais obtidos para que possa discutir a performance do seu classificador.\n",
    "##### Explique como são tratadas as mensagens com dupla negação e sarcasmo.\n",
    "##### Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A performance de nosso classificador não foi tão boa quanto o esperado, com um acerto médio percentual de classificação dos tweets (verdadeiros de cada categoria) de cerca de 47,25%. A categoria mais classificada de acordo com a nossa classificação foi a de tweets irrelevantes.\n",
    "\n",
    "Isso provavelmente se deve a vários fatores, como a dificuldade do classificador em entender tweets com sarcasmo, ironia, gírias, memes, entre outros, e o fato de que a diferença entre tweets relevantes e muito relevantes foi muito sutil.\n",
    "\n",
    "Também pode ter havido muitas divergências durante o processo de classificação dos tweets, pois se tratava de três pessoas diferentes realizando a categorização em um curto período de tempo. Assim, caso a equipe recebesse um financiamento, poderia investir em um treinamento/capacitação para classificar os tweets de forma mais semelhante.\n",
    "\n",
    "Além disso, o projeto poderia ser expandido para classificar uma quantidade maior de tweets relacionados à Catupiry e encaminhar estratégias para trabalhar com Marketing. Por exemplo, o projeto poderia reconhecer perfis (por meio dos @s) populares e frequentemente mencionados nesses tweets para possivelmente realizar parcerias para divulgação, ou então reconhecer memes e outras possíveis abordagens atraentes ao público-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizarmos o próprio classificador para classificar (como irrelevantes, neutros, relevantes ou muito relevantes) tweets selecionados, ao usarmos esses mesmos tweets para treinamento, e .\n",
    "\n",
    "Existe o risco do programa classificar o tweet de maneira errada e, quando for utilizar suas palavras como base para classificar outros tweets nessa categoria, terá muito mais chances de fazer classificações equivocadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propor diferentes cenários de uso para o classificador Naive-Bayes. Pense em outros cenários sem intersecção com este projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer. Indique material de pesquisa sobre o assunto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis OK\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação OK\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B) OK\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
