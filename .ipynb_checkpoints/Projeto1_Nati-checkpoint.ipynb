{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Isabelle Moschini Murollo\n",
    "\n",
    "Nome: Maia Fleider\n",
    "\n",
    "Nome: Natália Queiroz Menezes Carreras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo catupiry.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "catupiry = 'catupiry.xlsx'\n",
    "if catupiry in os.listdir():\n",
    "    print(f'Encontrei o arquivo {catupiry}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {catupiry} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>RELEVANCIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>viciei em hambúrguer com catupiry rota, por qu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@balalirica empadão de frango com catupiry fei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coisas inúteis sobre mim\\naltura — 1,78\\nidade...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uma pizza de frango com catupiry no café da manhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nossa queria uma pizza de frango com catupiry ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  RELEVANCIA\n",
       "0  viciei em hambúrguer com catupiry rota, por qu...           3\n",
       "1  @balalirica empadão de frango com catupiry fei...           1\n",
       "2  coisas inúteis sobre mim\\naltura — 1,78\\nidade...           2\n",
       "3  uma pizza de frango com catupiry no café da manhã           1\n",
       "4  nossa queria uma pizza de frango com catupiry ...           2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(catupiry)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>RELEVANCIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoje eu sonhei que tava de rolê aqui pertinho ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@essediafoilouco pizza de frango com catupiry ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jubaqueen frango com catupiry e banana com ca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@df_porto a @tweetsdaphri não é mineira, mas é...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>isso aqui! (tirando a parte de encher a cara, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  RELEVANCIA\n",
       "0  hoje eu sonhei que tava de rolê aqui pertinho ...           0\n",
       "1  @essediafoilouco pizza de frango com catupiry ...           2\n",
       "2  @jubaqueen frango com catupiry e banana com ca...           2\n",
       "3  @df_porto a @tweetsdaphri não é mineira, mas é...           0\n",
       "4  isso aqui! (tirando a parte de encher a cara, ...           0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(catupiry, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nós consideramos que os tweets mais relevantes para o produto seriam aqueles que realizassem comentários positivos ou comentários negativos, enquanto os menos relevantes seriam não relacionados diretamente ao produto.\n",
    "\n",
    "Assim, construímos a seguinte escala:\n",
    "\n",
    "0 - comentários não relacionados (irrelevante)\n",
    "\n",
    "1 - comentários neutros ou que não agregassem ao produto (neutro)\n",
    "\n",
    "2 - comentários positivos e elogios (relevante)\n",
    "\n",
    "3 - comentários que envolviam sentimentos positivos muito fortes ou comentários negativos (muito relevante)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importando as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorizando as classificações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para o treinamento\n",
    "train['RELEVANCIA']=train['RELEVANCIA'].astype('category')\n",
    "\n",
    "train['RELEVANCIA'].cat.categories = ['Irrelevante', 'Neutro', 'Relevante', 'Muito Relevante']\n",
    "\n",
    "filtra_irrelevantes = train['RELEVANCIA']=='Irrelevante'\n",
    "filtra_neutro = train['RELEVANCIA']=='Neutro'\n",
    "filtra_relevante = train['RELEVANCIA']=='Relevante'\n",
    "filtra_muito_relevante = train['RELEVANCIA']=='Muito Relevante'\n",
    "\n",
    "irrelevante = train.loc[filtra_irrelevantes,:]\n",
    "neutro = train.loc[filtra_neutro,:]\n",
    "relevante = train.loc[filtra_relevante,:]\n",
    "muito_relevante = train.loc[filtra_muito_relevante,:]\n",
    "\n",
    "#Para o teste\n",
    "test['RELEVANCIA']=test['RELEVANCIA'].astype('category')\n",
    "\n",
    "test['RELEVANCIA'].cat.categories = ['Irrelevante', 'Neutro', 'Relevante', 'Muito Relevante']\n",
    "\n",
    "filtra_irrelevantes_teste = test['RELEVANCIA']=='Irrelevante'\n",
    "filtra_neutro_teste = test['RELEVANCIA']=='Neutro'\n",
    "filtra_relevante_teste = test['RELEVANCIA']=='Relevante'\n",
    "filtra_muito_relevante_teste = test['RELEVANCIA']=='Muito Relevante'\n",
    "\n",
    "irrelevante_teste = test.loc[filtra_irrelevantes_teste,:]\n",
    "neutro_teste = test.loc[filtra_neutro_teste,:]\n",
    "relevante_teste = test.loc[filtra_relevante_teste,:]\n",
    "muito_relevante_teste = test.loc[filtra_muito_relevante_teste,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imprimindo as classificações categorizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(irrelevante)\\nprint(neutro)\\nprint(relevante)\\nprint(muito_relevante)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(irrelevante)\n",
    "print(neutro)\n",
    "print(relevante)\n",
    "print(muito_relevante)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criando as funções para limpeza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "#REMOVENDO PONTUAÇÕES:\n",
    "def cleanup(tweet):\n",
    "    punctuation = '[!-.:?;\\\"\\n()\\',—•]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    tweet_subbed = re.sub(pattern, '', tweet)\n",
    "    return tweet_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhttp(tweet):\n",
    "    site = 'http[^\\s]*'\n",
    "    pattern = re.compile(site)\n",
    "    tweet_subbed_site = re.sub(pattern, '', tweet)\n",
    "    return tweet_subbed_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_emoji(texto):\n",
    "    novo_texto = ''\n",
    "    for character in texto:\n",
    "        if character in emoji.UNICODE_EMOJI:\n",
    "            novo_texto += ' ' + character + ' '\n",
    "        else:\n",
    "            novo_texto += character\n",
    "    return novo_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def clean_palavras(tweet):\n",
    "    palavras = tweet.split()\n",
    "    novo_tweet = ''\n",
    "    lista = ['a', 'e', 'o', 'em', 'de', 'da', 'do', 'eh', 'é', 'que', 'q', 'pra', 'pro', 'para', 'com', 'cm', 'por']\n",
    "    for palavra in palavras:\n",
    "        if palavra in lista:\n",
    "            novo_tweet += ''\n",
    "        else:\n",
    "            novo_tweet += palavra\n",
    "    return novo_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_palavras2(lista):\n",
    "    nova_lista = []\n",
    "    lista_palavras = ['a', 'e', 'o', 'em', 'de', 'da', 'do', 'eh', 'é', 'que', 'q', 'pra', 'pro', 'para', 'com', 'cm', 'por']\n",
    "    for palavra in lista:\n",
    "        if palavra in lista_palavras:\n",
    "            nova_lista.append('')\n",
    "        else:\n",
    "            nova_lista.append(palavra)\n",
    "    return nova_lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementando as funções para limpeza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espaçando as frases uma das outras:\n",
    "treinamento_string = \"\"\n",
    "for tweet in train.Treinamento:\n",
    "    treinamento_string += \" \"+tweet\n",
    "    \n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower = cleanup(treinamento_string.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site = cleanhttp(treinamento_lower)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis = clean_emoji(treinamento_site)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento = treinamento_emojis.split()\n",
    "\n",
    "#Tirando palavras pouco relevantes, como preposições:\n",
    "tweet_sem_palavras = clean_palavras2(separacao_treinamento) #CORRIGIR\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento = pd.Series(tweet_sem_palavras)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IRRELEVANTES:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_irrelevantes = \"\"\n",
    "for i in irrelevante.Treinamento:\n",
    "    treinamento_irrelevantes += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_irrelevantes = cleanup(treinamento_irrelevantes.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_irrelevantes = cleanhttp(treinamento_lower_irrelevantes)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_irrelevantes = clean_emoji(treinamento_site_irrelevantes)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_irrelevantes = treinamento_emojis_irrelevantes.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_irrelevantes = pd.Series(separacao_treinamento_irrelevantes)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEUTRO:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_neutro = \"\"\n",
    "for i in neutro.Treinamento:\n",
    "    treinamento_neutro += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_neutro = cleanup(treinamento_neutro.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_neutro = cleanhttp(treinamento_lower_neutro)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_neutro = clean_emoji(treinamento_site_neutro)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_neutro = treinamento_emojis_neutro.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_neutro = pd.Series(separacao_treinamento_neutro)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(serie_treinamento_neutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RELEVANTES:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_relevantes = \"\"\n",
    "for i in relevante.Treinamento:\n",
    "    treinamento_relevantes += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_relevantes = cleanup(treinamento_relevantes.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_relevantes = cleanhttp(treinamento_lower_relevantes)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_relevantes = clean_emoji(treinamento_site_relevantes)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_relevantes = treinamento_emojis_relevantes.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_relevantes = pd.Series(separacao_treinamento_relevantes)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUITO RELEVANTES:\n",
    "#Espaçando as frases uma das outras:\n",
    "treinamento_muito_relevantes = \"\"\n",
    "for i in muito_relevante.Treinamento:\n",
    "    treinamento_muito_relevantes += \" \"+i\n",
    "\n",
    "#Deixando tudo em letras minúsculas:\n",
    "treinamento_lower_muito_relevantes = cleanup(treinamento_muito_relevantes.lower())\n",
    "\n",
    "#Apagando links:\n",
    "treinamento_site_muito_relevantes = cleanhttp(treinamento_lower_muito_relevantes)\n",
    "\n",
    "#Separando emojis:\n",
    "treinamento_emojis_muito_relevantes = clean_emoji(treinamento_site_muito_relevantes)\n",
    "\n",
    "#Separando as palavras:\n",
    "separacao_treinamento_muito_relevantes = treinamento_emojis_muito_relevantes.split()\n",
    "\n",
    "#Transformando lista de palavras em tabela de palavras:\n",
    "serie_treinamento_muito_relevantes = pd.Series(separacao_treinamento_muito_relevantes)\n",
    "\n",
    "#Imprimindo a tabela de palavras:\n",
    "#print(separacao_treinamento_muito_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabelas de frequencias absolutas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de treinamento:\n",
    "frequencia_absoluta_total = serie_treinamento.value_counts()\n",
    "\n",
    "# Tabela de tweets irrelevantes:\n",
    "frequencia_absoluta_irrelevante = serie_treinamento_irrelevantes.value_counts()\n",
    "\n",
    "# Tabela de tweets neutros:\n",
    "frequencia_absoluta_neutro = serie_treinamento_neutro.value_counts()\n",
    "\n",
    "# Tabela de tweets relevantes:  \n",
    "frequencia_absoluta_relevante = serie_treinamento_relevantes.value_counts()\n",
    "    \n",
    "# Tabela de tweets irrelevantes:\n",
    "frequencia_absoluta_muito_relevante = serie_treinamento_muito_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_neutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_relevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(frequencia_absoluta_muito_relevante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Teorema Naive-Bayes:\n",
    "###### Adicionando variáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1e-6   \n",
    "v = 1e6  #palavras totais na língua portuguesa/usadas no twitter\n",
    "\n",
    "lista_NB = [] #lista do Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando as probabilidades\n",
    "P_irrelevante = frequencia_absoluta_irrelevante.sum() / frequencia_absoluta_total.sum()\n",
    "P_neutro = frequencia_absoluta_neutro.sum() / frequencia_absoluta_total.sum()\n",
    "P_relevante = frequencia_absoluta_relevante.sum() / frequencia_absoluta_total.sum()\n",
    "P_muito_relevante = frequencia_absoluta_muito_relevante.sum() / frequencia_absoluta_total.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(P_irrelevante)\n",
    "print(P_neutro)\n",
    "print(P_relevante)\n",
    "print(P_muito_relevante)\n",
    "print(P_irrelevante+P_neutro+P_relevante+P_muito_relevante)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(irrelevante_teste)\n",
    "print(neutro_teste)\n",
    "print(relevante_teste)\n",
    "print(muito_relevante_teste)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "def score(tweet, prob, prior):\n",
    "    log1 = 0\n",
    "    for palavra in tweet:\n",
    "        log1 += log(prob) #somatória\n",
    "        \n",
    "    log2 = log(prior)\n",
    "    \n",
    "    log3 = log(a/(frequencia_absoluta_total + a*v))\n",
    "    \n",
    "    return (log1 + log2 + log3)\n",
    "    \n",
    "    #P_irrelevante_dado_tweet_vezes_P_tweet = P_tweet_dado_irrelevante*P_irrelevante\n",
    "'''   \n",
    "if score(tweet, P_tweet_dado_irrelevante, P_irrelevante) > score(tweet, P_tweet_dado_relevante, P_relevante) \\\n",
    "    and P_irrelevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "    and P_irrelevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\n",
    "    lista_NB.append(\"Irrelevante\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in test.Teste:    \n",
    "    #Deixando tudo em letras minúsculas:\n",
    "    teste_lower = cleanup(tweet.lower())\n",
    "\n",
    "    #Apagando links:\n",
    "    teste_site = cleanhttp(teste_lower)\n",
    "\n",
    "    #Separando emojis:\n",
    "    teste_emojis = clean_emoji(teste_site)\n",
    "\n",
    "    #Separando as palavras:\n",
    "    separacao_teste = teste_emojis.split()\n",
    "    \n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser irrelevante:\n",
    "    P_tweet_dado_irrelevante = 1\n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_irrelevante:\n",
    "            P_i_dado_irrelevante = (frequencia_absoluta_irrelevante[i] + a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_irrelevante = (a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        P_tweet_dado_irrelevante *= P_i_dado_irrelevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser neutro:\n",
    "    P_tweet_dado_neutro = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_neutro:\n",
    "            P_i_dado_neutro = (frequencia_absoluta_neutro[i] + a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_neutro = (a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        P_tweet_dado_neutro *= P_i_dado_neutro\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser relevante:\n",
    "    P_tweet_dado_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_relevante:\n",
    "            P_i_dado_relevante = (frequencia_absoluta_relevante[i] + a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_relevante = (a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        P_tweet_dado_relevante *= P_i_dado_relevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser muito relevante:\n",
    "    P_tweet_dado_muito_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_muito_relevante:\n",
    "            P_i_dado_muito_relevante = (frequencia_absoluta_muito_relevante[i] + a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_muito_relevante = (a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        P_tweet_dado_muito_relevante *= P_i_dado_muito_relevante\n",
    "        \n",
    "        \n",
    "    # Comparando as probabilidades utilizando o método Naive-Bayes \n",
    "    if score(tweet, P_tweet_dado_irrelevante, P_irrelevante) > score(tweet, P_tweet_dado_relevante, P_relevante) \\\n",
    "        and score(tweet, P_tweet_dado_irrelevante, P_irrelevante) > score(tweet, P_tweet_dado_neutro, P_neutro) \\\n",
    "        and score(tweet, P_tweet_dado_irrelevante, P_irrelevante) > score(tweet, P_tweet_dado_muito_relevante, P_muito_relevante):\n",
    "        lista_NB.append(\"Irrelevante\")\n",
    "        \n",
    "    elif score(tweet, P_tweet_dado_neutro, P_neutro) > score(tweet, P_tweet_dado_irrelevante, P_irrelevante) \\\n",
    "        and score(tweet, P_tweet_dado_neutro, P_neutro) > score(tweet, P_tweet_dado_relevante, P_relevante) \\\n",
    "        and score(tweet, P_tweet_dado_neutro, P_neutro) > score(tweet, P_tweet_dado_muito_relevante, P_muito_relevante):\n",
    "        lista_NB.append(\"Neutro\")\n",
    "        \n",
    "    elif score(tweet, P_tweet_dado_relevante, P_relevante) > score(tweet, P_tweet_dado_irrelevante, P_irrelevante) \\\n",
    "        and score(tweet, P_tweet_dado_relevante, P_relevante) > score(tweet, P_tweet_dado_neutro, P_neutro) \\\n",
    "        and score(tweet, P_tweet_dado_relevante, P_relevante) > score(tweet, P_tweet_dado_muito_relevante, P_muito_relevante):\n",
    "        lista_NB.append(\"Relevante\")\n",
    "    \n",
    "    elif score(tweet, P_tweet_dado_muito_relevante, P_muito_relevante) > score(tweet, P_tweet_irrelevante, P_irrelevante) \\\n",
    "        and score(tweet, P_tweet_dado_muito_relevante, P_muito_relevante) > score(tweet, P_tweet_neutro, P_neutro) \\\n",
    "        and score(tweet, P_tweet_dado_muito_relevante, P_muito_relevante) > score(tweet, P_tweet_relevante, P_relevante):\n",
    "        lista_NB.append(\"Muito Relevante\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in test.Teste:    \n",
    "    #Deixando tudo em letras minúsculas:\n",
    "    teste_lower = cleanup(tweet.lower())\n",
    "\n",
    "    #Apagando links:\n",
    "    teste_site = cleanhttp(teste_lower)\n",
    "\n",
    "    #Separando emojis:\n",
    "    teste_emojis = clean_emoji(teste_site)\n",
    "\n",
    "    #Separando as palavras:\n",
    "    separacao_teste = teste_emojis.split()\n",
    "    \n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser irrelevante:\n",
    "    P_tweet_dado_irrelevante = 1\n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_irrelevante:\n",
    "            P_i_dado_irrelevante = (frequencia_absoluta_irrelevante[i] + a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_irrelevante = (a) / (frequencia_absoluta_irrelevante.sum() + a*v)\n",
    "        P_tweet_dado_irrelevante *= P_i_dado_irrelevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser neutro:\n",
    "    P_tweet_dado_neutro = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_neutro:\n",
    "            P_i_dado_neutro = (frequencia_absoluta_neutro[i] + a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_neutro = (a) / (frequencia_absoluta_neutro.sum() + a*v)\n",
    "        P_tweet_dado_neutro *= P_i_dado_neutro\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser relevante:\n",
    "    P_tweet_dado_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_relevante:\n",
    "            P_i_dado_relevante = (frequencia_absoluta_relevante[i] + a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_relevante = (a) / (frequencia_absoluta_relevante.sum() + a*v)\n",
    "        P_tweet_dado_relevante *= P_i_dado_relevante\n",
    "    \n",
    "    # Calculando a probabilidade do tweet ser muito relevante:\n",
    "    P_tweet_dado_muito_relevante = 1 \n",
    "    for i in separacao_teste:\n",
    "        if i in frequencia_absoluta_muito_relevante:\n",
    "            P_i_dado_muito_relevante = (frequencia_absoluta_muito_relevante[i] + a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        else:\n",
    "            P_i_dado_muito_relevante = (a) / (frequencia_absoluta_muito_relevante.sum() + a*v)\n",
    "        P_tweet_dado_muito_relevante *= P_i_dado_muito_relevante\n",
    "        \n",
    "        \n",
    "    # Comparando as probabilidades utilizando o método Naive-Bayes \n",
    "    P_irrelevante_dado_tweet_vezes_P_tweet = P_tweet_dado_irrelevante*P_irrelevante\n",
    "    P_neutro_dado_tweet_vezes_P_tweet = P_tweet_dado_neutro*P_neutro\n",
    "    P_relevante_dado_tweet_vezes_P_tweet = P_tweet_dado_relevante*P_relevante\n",
    "    P_muito_relevante_dado_tweet_vezes_P_tweet = P_tweet_dado_muito_relevante*P_muito_relevante\n",
    "    \n",
    "    if  P_irrelevante_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_irrelevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "        and P_irrelevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\n",
    "        lista_NB.append(\"Irrelevante\")\n",
    "        \n",
    "    if P_neutro_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_neutro_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_neutro_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet:\n",
    "        lista_NB.append(\"Neutro\")\n",
    "        \n",
    "    if P_relevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "        and P_relevante_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_relevante_dado_tweet_vezes_P_tweet>P_muito_relevante_dado_tweet_vezes_P_tweet :\n",
    "        lista_NB.append(\"Relevante\")\n",
    "    \n",
    "    if P_muito_relevante_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet \\\n",
    "        and P_muito_relevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet \\\n",
    "        and P_muito_relevante_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet:\n",
    "        lista_NB.append(\"Muito Relevante\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['RELEVANCIA (Naive Bayes)'] = lista_NB\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "total_irrelevantes = 0\n",
    "total_neutros = 0\n",
    "total_relevantes = 0\n",
    "total_muitorelevantes = 0\n",
    "\n",
    "verdadeiros_irrelevantes = 0\n",
    "falsos_irrelevantes = 0\n",
    "\n",
    "verdadeiros_neutros = 0\n",
    "falsos_neutros = 0\n",
    "\n",
    "verdadeiros_relevantes = 0\n",
    "falsos_relevantes = 0\n",
    "\n",
    "verdadeiros_muitorelevantes = 0\n",
    "falsos_muitorelevantes = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for index, row in test.iterrows():\n",
    "    if row['RELEVANCIA']==\"Irrelevante\":\n",
    "        total_irrelevantes+=1\n",
    "        \n",
    "    if row['RELEVANCIA']==\"Neutro\":\n",
    "        total_neutros+=1     \n",
    "        \n",
    "    if row['RELEVANCIA']==\"Relevante\":\n",
    "        total_relevantes+=1\n",
    "        \n",
    "    if row['RELEVANCIA']==\"Muito Relevante\":\n",
    "        total_muitorelevantes+=1\n",
    "        \n",
    "        \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Irrelevante\":\n",
    "        if row['RELEVANCIA']==\"Irrelevante\":\n",
    "            verdadeiros_irrelevantes+=1\n",
    "        else:\n",
    "            falsos_irrelevantes+=1\n",
    "    \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Neutro\":\n",
    "        if row['RELEVANCIA']==\"Neutro\":\n",
    "            verdadeiros_neutros+=1\n",
    "        else:\n",
    "            falsos_neutros+=1\n",
    "    \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Relevante\":\n",
    "        if row['RELEVANCIA']==\"Relevante\":\n",
    "            verdadeiros_relevantes+=1\n",
    "        else:\n",
    "            falsos_relevantes+=1\n",
    "        \n",
    "    if row['RELEVANCIA (Naive Bayes)'] == \"Muito Relevante\":\n",
    "        if row['RELEVANCIA']==\"Muito Relevante\":\n",
    "            verdadeiros_muitorelevantes+=1\n",
    "        else:\n",
    "            falsos_muitorelevantes+=1   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "P_verdadeiros_irrelevantes = verdadeiros_irrelevantes/total_irrelevantes\n",
    "P_falsos_irrelevantes = falsos_irrelevantes/total_irrelevantes\n",
    "\n",
    "P_verdadeiros_neutros = verdadeiros_neutros/total_neutros\n",
    "P_falsos_neutros = falsos_neutros/total_neutros\n",
    "\n",
    "P_verdadeiros_relevantes = verdadeiros_relevantes/total_relevantes\n",
    "P_falsos_relevantes = falsos_relevantes/total_relevantes\n",
    "\n",
    "P_verdadeiros_muitorelevantes = verdadeiros_muitorelevantes/total_muitorelevantes\n",
    "P_falsos_muitorelevantes = falsos_muitorelevantes/total_muitorelevantes\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('Mensagens irrelevantes e que são classificadas como irrelevantes: ', P_verdadeiros_irrelevantes)\n",
    "print('Mensagens irrelevantes e que NÃO são classificadas como irrelevantes: ', P_falsos_irrelevantes)\n",
    "print(P_verdadeiros_irrelevantes+P_falsos_irrelevantes)\n",
    "print()\n",
    "\n",
    "print('Mensagens neutras e que são classificadas como neutras: ', P_verdadeiros_neutros)\n",
    "print('Mensagens neutras e que NÃO são classificadas como neutras: ', P_falsos_neutros)\n",
    "print(P_verdadeiros_neutros+P_falsos_neutros)\n",
    "print()\n",
    "\n",
    "print('Mensagens relevantes e que são classificadas como relevantes: ', P_verdadeiros_relevantes)\n",
    "print('Mensagens relevantes e que NÃO são classificadas como relevantes: ', P_falsos_relevantes)\n",
    "print(P_verdadeiros_relevantes+P_falsos_relevantes)\n",
    "print()\n",
    "\n",
    "print('Mensagens muito relevantes e que são classificadas como muito relevantes: ', P_verdadeiros_muitorelevantes)\n",
    "print('Mensagens muito relevantes e que NÃO são classificadas como muito relevantes: ', P_falsos_muitorelevantes)\n",
    "print(P_verdadeiros_muitorelevantes+P_falsos_muitorelevantes)\n",
    "\n",
    "print()\n",
    "print(P_verdadeiros_muitorelevantes+P_falsos_muitorelevantes+\\\n",
    "     P_verdadeiros_relevantes+P_falsos_relevantes+\\\n",
    "     P_verdadeiros_neutros+P_falsos_neutros+\\\n",
    "     P_verdadeiros_irrelevantes+P_falsos_irrelevantes)\n",
    "\n",
    "print()\n",
    "print((P_verdadeiros_muitorelevantes+P_verdadeiros_relevantes+\\\n",
    "      P_verdadeiros_neutros+P_verdadeiros_irrelevantes)/4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = pd.crosstab(train['RELEVANCIA'], test['RELEVANCIA (Naive Bayes)'], normalize='all')\n",
    "tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{(tabela.iloc[0,0] + tabela.iloc[1,2] + tabela.iloc[2,3] + tabela.iloc[3,1])*100.5}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby(by=\"RELEVANCIA\").describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby(by=\"RELEVANCIA (Naive Bayes)\").describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faça um comparativo qualitativo sobre os percentuais obtidos para que possa discutir a performance do seu classificador.\n",
    "##### Explique como são tratadas as mensagens com dupla negação e sarcasmo.\n",
    "##### Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A performance de nosso classificador não foi tão boa quanto o esperado, com um acerto médio percentual de classificação dos tweets (verdadeiros de cada categoria) de cerca de 47,25%. A categoria mais classificada de acordo com a nossa classificação foi a de tweets irrelevantes.\n",
    "\n",
    "Isso provavelmente se deve a vários fatores, como a dificuldade do classificador em entender tweets com sarcasmo, ironia, gírias, memes, entre outros, e o fato de que a diferença entre tweets relevantes e muito relevantes foi muito sutil.\n",
    "\n",
    "Também pode ter havido muitas divergências durante o processo de classificação dos tweets, pois se tratava de três pessoas diferentes realizando a categorização em um curto período de tempo. Assim, caso a equipe recebesse um financiamento, poderia investir em um treinamento/capacitação para classificar os tweets de forma mais semelhante.\n",
    "\n",
    "Além disso, o projeto poderia ser expandido para classificar uma quantidade maior de tweets relacionados à Catupiry e encaminhar estratégias para trabalhar com Marketing. Por exemplo, o projeto poderia reconhecer perfis (por meio dos @s) populares e frequentemente mencionados nesses tweets para possivelmente realizar parcerias para divulgação, ou então reconhecer memes e outras possíveis abordagens atraentes ao público-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizarmos o próprio classificador para classificar (como irrelevantes, neutros, relevantes ou muito relevantes) tweets selecionados, ao usarmos esses mesmos tweets para treinamento, e .\n",
    "\n",
    "Existe o risco do programa classificar o tweet de maneira errada e, quando for utilizar suas palavras como base para classificar outros tweets nessa categoria, terá muito mais chances de fazer classificações equivocadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propor diferentes cenários de uso para o classificador Naive-Bayes. Pense em outros cenários sem intersecção com este projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer. Indique material de pesquisa sobre o assunto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis OK\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação OK\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B) OK\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
